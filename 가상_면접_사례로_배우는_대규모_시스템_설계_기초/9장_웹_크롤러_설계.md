### 웹 크롤러가 사용되는 곳

- 검색 엔진 인덱싱: 웹 페이지를 모아 검색 엔진을 위한 로컬 인덱스를 만듬
- 웹 아카이빙: 나중에 사용할 목적으로 장기보관하기 위해 웹에서 정보를 모으는 절차
- 웹 마이닝
- 웹 모니터링

# 1단계. 문제 이해 및 설계 범위 확정

- 규모 확장성
- 안정성
- 예절
- 확장성

# 2단계. 개략적 설계안 제시 및 동의 구하기

## 시작 URL 집합

웹 크롤러가 크롤링을 시작하는 출발점

## 미수집 URL 저장소

### 크롤링 상태

- 다운로드할 URL
    - 이것을 저장 관리하는 컴포넌트를 미수집 URL 저장소라고 부름, FIFO
- 다운로드된 URL

## HTML 라운로더

인터넷에서 웹 페이지를 다운로드하는 컴포넌트

## 도메인 이름 변환기

url을 ip주소로 변환

## 콘텐츠 파서

웹페이지를 다운로드 후 파싱과 검증

## 중복된 콘텐츠

웹 페이지의 해시값 비교

## 콘텐츠 저장소

HTML 문서를 보관하는 시스템

- 데이터 양이 많으므로 대부분의 콘텐츠는 디스크에 저장
- 인기 있는 콘텐츠는 메모리에 두어 접근 지연시간 줄임

## URL 추출기

HTML 페이지를 파싱하여 링크들을 골라냄

상대경로는 모두 절대경로로 변환

## URL 필터

콘텐츠 타입, 오류 발생, 접근 제외 목록에 따라 필터링

## 방문한 URL

블룸 필터나 해시테이블로 중복 방지

## URL 저장소

이미 방문한 URL 저장

# 3단계. 상세 설계

## DFS vs BFS

페이지는 노드, 하이퍼 링크는 에지

그래프 크기가 클 수 있기 때문에 보통 BFS를 사용한다.

### BFS의 문제점

- 같은 호스트에 속한 링크를 계속 참조하게 되는데, 이로 인해 서버가 과부하 걸릴 수 있음
- URL 간의 우선 순위가 없음

## 미수집 URL 저장소

### 예의

동일 웹 사이트에 대해서는 한 번에 한 페이지만 요청

- 큐 라우터: 같은 호스트에 속한 URL은 항상 같은 큐에 저장
- 매핑 테이블: 호스트 이름과 큐 매핑
- FIFO 큐
- 큐 선택기
- 작업 스레드

### 신선도

주기적으로 재수집해야 함

- 웹 페이지의 변경 이력 활용
- 우선순위를 활용하여 중요한 페이지는 좀 더 자주 재수집

## HTML 다운로더

### Robots.txt

수집해도 되는 페이지 목록

### 성능 최적화

1. 분산 크롤링
    
    성능을 높이기 위해 크롤링 작업을 여러 서버에 분산
    
2. 도메인 이름 변환 결과 캐시
    
    도메인 이름과 IP주소 관계를 캐시에 보관한 뒤 크론 잡으로 주기적으로 갱신
    
3. 지역성
    
    크롤링 작업을 수행하는 서버를 지역별로 분산
    
4. 짧은 타임아웃
    
    서버가 응답하지 않으면 해당 페이지 다운로드를 중단하고 다음 페이지로 넘어감
    

### 안정성

- 안정 해시
- 트롤링 상태 및 수집 데이터 저장
- 예외 처리 데이터 검증

### 문제 있는 콘텐츠 감지 및 회피

- 중복 콘텐츠
- 거미 덫
- 데이터 노이즈

# 4단계. 마무리

### 논의해보면 좋을 점

- 서버 측 렌더링
- 원치 않는 페이지 필터링
- 데이터베이스 다중화 및 샤딩
- 수평적 규모 확장성
- 가용성, 일관성, 안정성
- 데이터 분석 솔루션
